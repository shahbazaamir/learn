{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef1e274-0a04-4393-af89-a41db9171fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamo: Amazon’s Highly Available Key-value Store \n",
      "Giuseppe DeCandia, Deniz Ha storun, Madan Jampani, Guna vardhan Kakulapati,  \n",
      "Avinash Lakshman, Alex Pilchin, Swam inathan Sivasubramanian, Peter Vosshall  \n",
      "and Werner Vogels \n",
      "Amazon.com \n",
      " \n",
      "ABSTRACT \n",
      "Reliability at massive scale is one of the biggest challenges we \n",
      "face at Amazon.com, one of the largest e-commerce operations in \n",
      "the world; even the slightest outage has significant financial \n",
      "consequences and impacts cust omer trust. The Amazon.c\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "pdf_path = \"amazon-dynamo-sosp2007.pdf\"\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "print(text[:500])  # Print the first 500 characters to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a08cdb6-ba67-428b-a6cd-9aadcfa39e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 208\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # Number of characters per chunk\n",
    "    chunk_overlap=50  # Overlap between chunks\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(text)\n",
    "print(f\"Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3df5d62-197d-4cc6-8661-e904b4d182a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Lightweight embedding model\n",
    "chunk_embeddings = embedding_model.encode(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a6a9cb-c87e-42bf-a1be-eb2a6b88a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Create a FAISS index\n",
    "dimension = chunk_embeddings.shape[1]  # Dimension of embeddings\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance for similarity search\n",
    "index.add(np.array(chunk_embeddings))  # Add embeddings to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8d48e98-9add-43ea-aca7-546a52fb1a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant chunks: ['read/write quorum characteristics. The following are the main \\npatterns in which Dynamo is used: \\n• Business logic specific reconciliation:  This is a popular use \\ncase for Dynamo. Each data object is replicated across multiple nodes. In case of dive rgent versions, the client \\napplication performs its ow n reconciliation logic. The \\nshopping cart service discussed ear lier is a prime example of \\nthis category. Its business l ogic reconciles objects by', 'reads) or storing data at one or more nodes (for writes). Each \\nclient request results in the crea tion of a state machine on the node \\nthat received the client request. The state machine contains all the \\nlogic for identifying the nodes responsible for a key, sending the \\nrequests, waiting for response s, potentially doing retries, \\nprocessing the replies and packag ing the response to the client. \\nEach state machine instance handles exactly one client request.', 'interface; it exposes two operations: get() and put(). The get( key) \\noperation locates the object replicas associated with the key in the \\nstorage system and returns a single object  or a list of objects with \\nconflicting versions along with a context . The put( key, context, \\nobject ) operation determines where the replicas of the object \\nshould be placed based on the associated key, and writes the \\nreplicas to disk. The context  encodes system metadata about the']\n"
     ]
    }
   ],
   "source": [
    "def retrieve_relevant_chunks(question, top_k=3):\n",
    "    question_embedding = embedding_model.encode([question])\n",
    "    distances, indices = index.search(question_embedding, top_k)\n",
    "    relevant_chunks = [chunks[i] for i in indices[0]]\n",
    "    return relevant_chunks\n",
    "\n",
    "question = \"What is the main topic of the document?\"\n",
    "relevant_chunks = retrieve_relevant_chunks(question)\n",
    "print(\"Relevant chunks:\", relevant_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a103ce2-e4fd-4c67-82f5-b12765379bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do we increase the availability?\"\n",
    "relevant_chunks = retrieve_relevant_chunks(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d27369e-6fbc-4b53-89a2-d74bf16c6bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be achieved under which conditions. \\nFor systems prone to server and network failures, availability can \\nbe increased by using optimistic  replication techniques, where \\nchanges are allowed to propagate to replicas in the background, \\nand concurrent, disconnected work  is tolerated.  The challenge \\nwith this approach is that it can  lead to conflicting changes which \\nmust be detected and resolved.  This process of conflict resolution',\n",
       " 'strict operational requirements on Amazon’s platform in terms of \\nperformance, reliabilit y and efficiency, and to support continuous \\ngrowth the platform needs to be highly scalable. Reliability is one \\nof the most important requirements because even the slightest \\noutage has significant financia l consequences and impacts \\ncustomer trust. In addition, to  support continuous growth, the \\nplatform needs to be highly scalable. One of the lessons our organiza tion has learned from operating',\n",
       " 'control. In the past, centralized control has resulted in outages and \\nthe goal is to avoid it as much as possible. This leads to a simpler, \\nmore scalable, and more available system. \\nHeterogeneity : The system needs to be able to exploit \\nheterogeneity in the infrastructur e it runs on. e.g. the work \\ndistribution must be proportional to the capabilities of the \\nindividual servers. This is e ssential in adding new nodes with \\nhigher capacity without having to upgrade all hosts at once.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46592de5-b2d7-45cf-8347-3184d11ec8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: optimising replication techniques\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained question-answering model\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "\n",
    "def generate_answer(question, relevant_chunks):\n",
    "    context = \" \".join(relevant_chunks)\n",
    "    input_text = f\"question: {question} context: {context}\"\n",
    "    answer = qa_pipeline(input_text, max_length=200)[0]['generated_text']\n",
    "    return answer\n",
    "\n",
    "answer = generate_answer(question, relevant_chunks)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c44d9339-5d84-451f-810f-b2a3dc9a7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How does Dynamodb handle server failure\"\n",
    "relevant_chunks = retrieve_relevant_chunks(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30be1821-0b0f-4038-9c8e-8e518d97fe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: asynchronous response\n"
     ]
    }
   ],
   "source": [
    "answer = generate_answer(question, relevant_chunks)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f99f4a32-54f1-4639-bc5b-54bae9cd4c73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7c4fd-71cb-4264-a725-5adfffe3eff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
